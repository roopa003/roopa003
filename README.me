import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
url = "https://www.kaggle.com/datasets/hijest/genre-classification-dataset-imdb/"
# Download the dataset from Kaggle and load it into a pandas DataFrame

# Assuming the dataset is loaded into a DataFrame called 'df'
# Make sure you replace the following line with the actual loading of your dataset
# df = pd.read_csv("path_to_your_dataset.csv")

# For the purpose of this example, let's create a small synthetic dataset
data = {
    'plot': ['A man discovers a hidden treasure in the jungle.',
             'A group of friends embarks on a space adventure.',
             'A detective solves a mysterious murder case.'],
    'genre': ['Adventure', 'Sci-Fi', 'Mystery']
}

df = pd.DataFrame(data)

# Split the dataset into training and testing sets
train_data, test_data, train_labels, test_labels = train_test_split(
    df['plot'], df['genre'], test_size=0.2, random_state=42
)

# Convert the text data into TF-IDF features
tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
train_features = tfidf_vectorizer.fit_transform(train_data)
test_features = tfidf_vectorizer.transform(test_data)

# Train a Naive Bayes classifier
classifier = MultinomialNB()
classifier.fit(train_features, train_labels)

# Make predictions on the test set
predictions = classifier.predict(test_features)

# Evaluate the performance of the model
accuracy = accuracy_score(test_labels, predictions)
print(f"Accuracy: {accuracy:.2f}")

# Display classification report
print("\nClassification Report:\n", classification_report(test_labels, predictions))
